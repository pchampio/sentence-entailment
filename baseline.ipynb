{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 380)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./sick_train/SICK_train.txt\", sep=\"\\t\")\n",
    "df = df.drop(['relatedness_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>entailment_judgment</th>\n",
       "      <th>entailment_id</th>\n",
       "      <th>sentence_AB</th>\n",
       "      <th>word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>A group of boys in a yard is playing and a man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, A, group, of, kids, is, playing, in, a, yard, and, an, old, man, is, standing, in, the, ba...</td>\n",
       "      <td>[1, 3, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, 11, 17, 10, 18, 7, 2, 3, 9, 14, 8, 10, 4, 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house and there is no man standing in the background</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, A, group, of, children, is, playing, in, the, house, and, there, is, no, man, standing, in...</td>\n",
       "      <td>[1, 3, 9, 14, 20, 11, 16, 10, 18, 21, 6, 23, 11, 22, 13, 17, 10, 18, 7, 2, 3, 9, 14, 12, 11, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the man is smiling nearby</td>\n",
       "      <td>The kids are playing outdoors near a man with a smile</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;s&gt;, The, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, &lt;sep&gt;, The, ...</td>\n",
       "      <td>[1, 24, 31, 8, 25, 16, 27, 6, 18, 13, 11, 29, 1000, 2, 24, 12, 25, 16, 27, 26, 4, 13, 30, 4, 28, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with a smile</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, The, kids, are, playing, outdoors, near, a, man, with, a, smile, &lt;sep&gt;, A, group, of, kids...</td>\n",
       "      <td>[1, 24, 12, 25, 16, 27, 26, 4, 13, 30, 4, 28, 2, 3, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the man is smiling nearby</td>\n",
       "      <td>A group of kids is playing in a yard and an old man is standing in the background</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;s&gt;, The, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, &lt;sep&gt;, A, gr...</td>\n",
       "      <td>[1, 24, 31, 8, 25, 16, 27, 6, 18, 13, 11, 29, 1000, 2, 3, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                                                                  sentence_A                                                                         sentence_B entailment_judgment  entailment_id                                                                                          sentence_AB  \\\n",
       "0        1           A group of kids is playing in a yard and an old man is standing in the background       A group of boys in a yard is playing and a man is standing in the background             NEUTRAL              0  [<s>, A, group, of, kids, is, playing, in, a, yard, and, an, old, man, is, standing, in, the, ba...   \n",
       "1        2  A group of children is playing in the house and there is no man standing in the background  A group of kids is playing in a yard and an old man is standing in the background             NEUTRAL              0  [<s>, A, group, of, children, is, playing, in, the, house, and, there, is, no, man, standing, in...   \n",
       "2        3                           The young boys are playing outdoors and the man is smiling nearby                              The kids are playing outdoors near a man with a smile          ENTAILMENT              1  [<s>, The, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, <sep>, The, ...   \n",
       "3        5                                       The kids are playing outdoors near a man with a smile  A group of kids is playing in a yard and an old man is standing in the background             NEUTRAL              0  [<s>, The, kids, are, playing, outdoors, near, a, man, with, a, smile, <sep>, A, group, of, kids...   \n",
       "4        9                           The young boys are playing outdoors and the man is smiling nearby  A group of kids is playing in a yard and an old man is standing in the background             NEUTRAL              0  [<s>, The, young, boys, are, playing, outdoors, and, the, man, is, smiling, nearby, <sep>, A, gr...   \n",
       "\n",
       "                                                                                              word_idx  \n",
       "0  [1, 3, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, 11, 17, 10, 18, 7, 2, 3, 9, 14, 8, 10, 4, 19,...  \n",
       "1  [1, 3, 9, 14, 20, 11, 16, 10, 18, 21, 6, 23, 11, 22, 13, 17, 10, 18, 7, 2, 3, 9, 14, 12, 11, 16,...  \n",
       "2  [1, 24, 31, 8, 25, 16, 27, 6, 18, 13, 11, 29, 1000, 2, 24, 12, 25, 16, 27, 26, 4, 13, 30, 4, 28, 0]  \n",
       "3  [1, 24, 12, 25, 16, 27, 26, 4, 13, 30, 4, 28, 2, 3, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15, 13, ...  \n",
       "4  [1, 24, 31, 8, 25, 16, 27, 6, 18, 13, 11, 29, 1000, 2, 3, 9, 14, 12, 11, 16, 10, 4, 19, 6, 5, 15...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SickDataset(Dataset):\n",
    "    endOfSentence   = '</s>'\n",
    "    startOfSentence = '<s>'\n",
    "    separator2Sentences = '<sep>'\n",
    "    \n",
    "    tokens = [startOfSentence, separator2Sentences, endOfSentence]\n",
    "    \n",
    "    def join_sentence(self, row):\n",
    "        \"\"\"\n",
    "        Create a new sentence (<s> + s_A + <sep> + s_B + </s>)\n",
    "        \"\"\"\n",
    "        sentence_a = row['sentence_A'].split(\" \")\n",
    "        sentence_b = row['sentence_B'].split(\" \")\n",
    "        return np.concatenate((\n",
    "            [self.startOfSentence],\n",
    "            sentence_a,\n",
    "            [self.separator2Sentences],\n",
    "            sentence_b,\n",
    "            [self.endOfSentence]\n",
    "        ))\n",
    "    \n",
    "    def series_text_2_labelID(self, series, keep_n=1000):\n",
    "        \"\"\"\n",
    "        Convert text Label into label id\n",
    "        \"\"\"\n",
    "        return series.map({\"NEUTRAL\": 0, \"ENTAILMENT\": 1, \"CONTRADICTION\": 2})\n",
    "    \n",
    "    def series_2_dict(self, series, keep_n):\n",
    "        \"\"\"\n",
    "        Convert document (a list of words) into a list of indexes\n",
    "        \"\"\"\n",
    "        dictionary = corpora.Dictionary(series)\n",
    "        dictionary.filter_extremes(\n",
    "            no_below=1,\n",
    "            no_above=1,\n",
    "            keep_n=keep_n,\n",
    "            keep_tokens=self.tokens)\n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    def __init__(self, df, vocabulary_size):\n",
    "        # Label text as ids\n",
    "        df[\"entailment_id\"] = self.series_text_2_labelID(df['entailment_judgment'])\n",
    "        \n",
    "        # Add <s>,</s>,<sep> tokens to the vocabulary\n",
    "        df['sentence_AB'] = df.apply(self.join_sentence, axis=1)\n",
    "        \n",
    "        # Create the Dictionary\n",
    "        self.dictionary = self.series_2_dict(df['sentence_AB'], vocabulary_size)\n",
    "        \n",
    "        # sentence of words -> array of idx\n",
    "        # Adds unknown to the voc, Dictionary size vocabulary_size+1\n",
    "        df[\"word_idx\"] = df[\"sentence_AB\"].apply(\n",
    "            lambda x: np.array(self.dictionary.doc2idx(x, unknown_word_index=vocabulary_size))\n",
    "        )\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "    def getRef(self, index):\n",
    "        return df['sentence_AB'][index]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            df['word_idx'][index],\n",
    "            df['entailment_id'][index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "vocabulary_size = 1000\n",
    "sick_dataset = SickDataset(df, vocabulary_size)\n",
    "sick_dataset.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>The</td>\n",
       "      <td>young</td>\n",
       "      <td>boys</td>\n",
       "      <td>are</td>\n",
       "      <td>playing</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>man</td>\n",
       "      <td>...</td>\n",
       "      <td>are</td>\n",
       "      <td>playing</td>\n",
       "      <td>outdoors</td>\n",
       "      <td>near</td>\n",
       "      <td>a</td>\n",
       "      <td>man</td>\n",
       "      <td>with</td>\n",
       "      <td>a</td>\n",
       "      <td>smile</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1      2     3    4        5         6    7    8    9   ...    16       17        18    19 20   21    22 23     24    25\n",
       "0  <s>  The  young  boys  are  playing  outdoors  and  the  man  ...   are  playing  outdoors  near  a  man  with  a  smile  </s>\n",
       "1    1   24     31     8   25       16        27    6   18   13  ...    25       16        27    26  4   13    30  4     28     0\n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(sick_dataset.getRef(2), sick_dataset[2][0]))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNClassifier(\n",
      "  (embedding): Embedding(1001, 200)\n",
      "  (rnn): RNN(200, 5, batch_first=True)\n",
      "  (fc): Linear(in_features=5, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_voc_size, embedding_size, hidden_size):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        \n",
    "        self.input_voc_size = input_voc_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.num_classes = 3\n",
    "        \n",
    "        # Add the unknown token\n",
    "        self.embedding = nn.Embedding(input_voc_size+1, embedding_size)\n",
    "        self.rnn = nn.RNN(\n",
    "              input_size=embedding_size,\n",
    "              hidden_size=hidden_size,\n",
    "              batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, self.num_classes)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        h_0 = torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"  input\", x.size())\n",
    "        emb = self.embedding(x)\n",
    "        emb = emb.view(1, x.size(0), -1)\n",
    "        if verbose:\n",
    "            print(\"  embedding\", emb.size())\n",
    "\n",
    "        # Propagate embedding through RNN\n",
    "        # Input: (batch, seq_len, embedding_size)\n",
    "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
    "        out, hidden = self.rnn(emb, h_0)\n",
    "        if verbose:\n",
    "            print(\"  rnn_out\", out.size())\n",
    "        return self.fc(hidden)\n",
    "    \n",
    "rnn = RNNClassifier(vocabulary_size, 200, 5)\n",
    "print(rnn)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,   24,   31,    8,   25,   16,   27,    6,   18,   13,   11,   29,\n",
      "        1000,    2,   24,   12,   25,   16,   27,   26,    4,   13,   30,    4,\n",
      "          28,    0])\n",
      "  input torch.Size([26])\n",
      "  embedding torch.Size([1, 26, 200])\n",
      "  rnn_out torch.Size([1, 26, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0831, -0.5896, -0.6353]]], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputEx = torch.tensor(sick_dataset[2][0])\n",
    "print(inputEx)\n",
    "rnn(inputEx, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, use this insted\n",
    "train_loader = DataLoader(dataset=sick_dataset,\n",
    "                          batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/info/etu/m2/s142293/lab/sick/venv/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [    0/4500 (0%)]\tLoss: inf\n",
      "Train Epoch: 0 [  201/4500 (4%)]\tLoss: 1.01\n",
      "Train Epoch: 0 [  402/4500 (9%)]\tLoss: 0.97\n",
      "Train Epoch: 0 [  603/4500 (13%)]\tLoss: 1.01\n",
      "Train Epoch: 0 [  804/4500 (18%)]\tLoss: 1.06\n",
      "Train Epoch: 0 [ 1005/4500 (22%)]\tLoss: 1.08\n",
      "Train Epoch: 0 [ 1206/4500 (27%)]\tLoss: 1.12\n",
      "Train Epoch: 0 [ 1407/4500 (31%)]\tLoss: 1.14\n",
      "Train Epoch: 0 [ 1608/4500 (36%)]\tLoss: 1.16\n",
      "Train Epoch: 0 [ 1809/4500 (40%)]\tLoss: 1.18\n",
      "Train Epoch: 0 [ 2010/4500 (45%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 2211/4500 (49%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 2412/4500 (54%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 2613/4500 (58%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 2814/4500 (63%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 3015/4500 (67%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 3216/4500 (71%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 3417/4500 (76%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 3618/4500 (80%)]\tLoss: 1.19\n",
      "Train Epoch: 0 [ 3819/4500 (85%)]\tLoss: 1.18\n",
      "Train Epoch: 0 [ 4020/4500 (89%)]\tLoss: 1.17\n",
      "Train Epoch: 0 [ 4221/4500 (94%)]\tLoss: 1.16\n",
      "Train Epoch: 0 [ 4422/4500 (98%)]\tLoss: 1.16\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dd695c6f6bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to use DataLoader for more epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msick_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0midx_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ceb021ff97f1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         return (\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             df['entailment_id'][index])\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/sick/venv/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/sick/venv/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4500"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "rnn = rnn\n",
    "total_loss = 0\n",
    "for epoch in range(1): # need to use DataLoader for more epochs\n",
    "    for i, (idx_sentence, target) in enumerate(sick_dataset):\n",
    "        idx_sentence = torch.tensor(idx_sentence)\n",
    "        target = torch.tensor([np.long(target)])\n",
    "        \n",
    "        output = rnn(idx_sentence)\n",
    "\n",
    "        loss = criterion(output[0], target)\n",
    "        total_loss += loss.data[0]\n",
    "\n",
    "        rnn.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 201 == 0:\n",
    "            print('Train Epoch: {} [{:5}/{} ({:.0f}%)]\\tLoss: {:.2f}'.format(\n",
    "                epoch,  i , len(sick_dataset),\n",
    "                100. * i  / len(train_loader),\n",
    "                total_loss / i ))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
